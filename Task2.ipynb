{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "421/421 [==============================] - 582s 1s/step - loss: 1.4721 - accuracy: 0.3085\n",
      "Epoch 2/2\n",
      "421/421 [==============================] - 567s 1s/step - loss: 1.4577 - accuracy: 0.3229\n",
      "422/422 [==============================] - 537s 1s/step\n",
      "106/106 [==============================] - 128s 1s/step\n",
      "Test Accuracy (Logistic Regression): 40.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "# Define your data directories and parameters\n",
    "train_data_dir = r'D:\\Research\\Neurodegenerative Diseases\\Images\\Task1\\Task1-Images\\MRI\\Training'\n",
    "test_data_dir = r'D:\\Research\\Neurodegenerative Diseases\\Images\\Task1\\Task1-Images\\MRI\\Testing'\n",
    "batch_size = 32\n",
    "image_size = (128, 128) \n",
    "num_epochs = 2\n",
    "num_classes = 5  # CN, AD, MCI, EMCI, LMCI\n",
    "\n",
    "# Function to load and preprocess images and labels\n",
    "def load_and_preprocess_images_and_labels(directory):\n",
    "    image_data = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".dcm\"):\n",
    "            dcm_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                dcm_data = pydicom.dcmread(dcm_path)\n",
    "                img = dcm_data.pixel_array.astype(np.float32) / 255.0\n",
    "                img = cv2.resize(img, image_size)\n",
    "                image_data.append(img)\n",
    "                \n",
    "                # Parse the filename to extract class name\n",
    "                filename_parts = filename.split('_')\n",
    "                class_name = filename_parts[-1].split('.')[0]\n",
    "                \n",
    "                # Map class names to class labels (you can customize this)\n",
    "                class_mapping = {'CN': 0, 'AD': 1, 'MCI': 2, 'EMCI': 3, 'LMCI': 4}\n",
    "                label = class_mapping.get(class_name, -1)  # Assign labels as needed\n",
    "                \n",
    "                if label != -1:\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    print(f\"Unknown class name: {class_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {dcm_path}: {str(e)}\")\n",
    "\n",
    "    return np.array(image_data), np.array(labels)\n",
    "\n",
    "# Load and preprocess training and testing data\n",
    "train_images, train_labels = load_and_preprocess_images_and_labels(train_data_dir)\n",
    "test_images, test_labels = load_and_preprocess_images_and_labels(test_data_dir)\n",
    "\n",
    "# Expand grayscale images to three channels (RGB)\n",
    "train_images = np.repeat(train_images[:, :, :, np.newaxis], 3, axis=-1)\n",
    "test_images = np.repeat(test_images[:, :, :, np.newaxis], 3, axis=-1)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "# Rest of your code remains the same...\n",
    "\n",
    "# Create a data generator for training images\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load the ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', input_shape=(128, 128, 3), include_top=False)\n",
    "\n",
    "# Modify the last layer of your model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)  # Use softmax activation\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the ResNet50 model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply oversampling only if the class distribution is imbalanced\n",
    "class_distribution = Counter(np.argmax(train_labels, axis=1))\n",
    "max_class_samples = max(class_distribution.values())\n",
    "\n",
    "if len(class_distribution) > 1 and max_class_samples < len(train_labels) / len(class_distribution):\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    train_images_resampled, train_labels_resampled = oversampler.fit_resample(\n",
    "        train_images.reshape(-1, image_size[0]*image_size[1]*3),\n",
    "        train_labels.argmax(axis=1)  # Use integer labels\n",
    "    )\n",
    "\n",
    "    # Convert integer labels to one-hot encoding\n",
    "    train_labels_resampled = tf.keras.utils.to_categorical(train_labels_resampled, num_classes)\n",
    "\n",
    "    # Train the model using the data generator\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        history = model.fit(\n",
    "            train_data_generator.flow(train_images_resampled, train_labels_resampled, batch_size=batch_size),\n",
    "            steps_per_epoch=len(train_images_resampled) // batch_size,\n",
    "            epochs=1,  # Train for one epoch at a time\n",
    "        )\n",
    "else:\n",
    "    # Train the model using the original unbalanced data\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        history = model.fit(\n",
    "            train_data_generator.flow(train_images, train_labels, batch_size=batch_size),\n",
    "            steps_per_epoch=len(train_images) // batch_size,\n",
    "            epochs=1,  # Train for one epoch at a time\n",
    "        )\n",
    "\n",
    "# Extract features from the Global Average Pooling layer\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "train_features = feature_extractor.predict(train_images)\n",
    "test_features = feature_extractor.predict(test_images)\n",
    "\n",
    "# Flatten the extracted features\n",
    "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
    "test_features_flat = test_features.reshape(test_features.shape[0], -1)\n",
    "\n",
    "# Apply Logistic Regression classifier\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(train_features_flat, train_labels.argmax(axis=1))\n",
    "test_predictions = classifier.predict(test_features_flat)\n",
    "\n",
    "# Calculate and print test accuracy\n",
    "test_accuracy = accuracy_score(np.argmax(test_labels, axis=1), test_predictions)\n",
    "print(f\"Test Accuracy (Logistic Regression): {test_accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
